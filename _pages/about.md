---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a recent graduate of the **Master's degree in Machine Learning** from **University College London**, where I was advised by **Professor Laura Toni** and **Professor Brooks Paige**. My [thesis project](https://ignasa007.github.io/files/msc-thesis_jasraj-singh.pdf) was on studying the negative effects of the DropEdge algorithm on over-squashing in GNNs, demonstrating its unsuitability at modelling long-range interactions. Upon graduation, I extended my thoeretical analysis to include other edge-dropping algorithms &ndash; DropNode, DropAgg and DropGNN. My empirical analysis also included popular algorithms for training deep GNNs, like Dropout, DropMessage, SkipNode, GraphSAGE and ResGCN, through which I demonstrated their negative effects on over-squashing and performance on heterophilic datasets. [Read more](https://ignasa007.github.io/publication/edge-dropping).

Previously, I earned a **Bachelor's degree in Mathematical and Computer Sciences** from **Nanyang Technological University**, supervised by **Professor Bryan Low** at National University of Singapore. My [thesis project](https://ignasa007.github.io/files/bsc-thesis_jasraj-singh.pdf) introduced *Expected Variance with Gaussian Processes* (EV-GP) &ndash; an active learning criterion based on the NTK theory, with initialization robustness guarantees. [Read more](https://ignasa007.github.io/publication/evgp).

I spent the summer between the two programs working under the supervision of **Professor Xu Hong** and **Liu Fang** at the **Visual and Cognitive Neuroscience Lab**. We introduced *LingML*, an efficient way of incorporating linguistic knowledge into LLMs, that performs competitively with state-of-the-art approaches at a fraction of computational cost. [Read more](https://ignasa007.github.io/publication/lingml).